{"version":3,"sources":["App.js","reportWebVitals.js","index.js"],"names":["App","textToCopy","setTextToCopy","useState","isCopied","setCopied","useClipboard","successDuration","typedText","setTypedText","darkMode","setDarkMode","transcript","browserSupportsSpeechRecognition","useSpeechRecognition","useEffect","document","body","classList","add","remove","React","createElement","className","onClick","toggleDarkMode","value","onChange","e","target","placeholder","startListening","SpeechRecognition","continuous","language","stopListening","clearText","reportWebVitals","onPerfEntry","Function","then","_ref","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","createRoot","getElementById","render","StrictMode"],"mappings":"+PAmEeA,MA7Df,WACE,MAAOC,EAAYC,GAAiBC,mBAAS,KACtCC,EAAUC,GAAaC,YAAaL,EAAY,CAAEM,gBAAiB,OACnEC,EAAWC,GAAgBN,mBAAS,KACpCO,EAAUC,GAAeR,oBAAS,IAGnC,WAAES,EAAU,iCAAEC,GAAqCC,iCAyBzD,OARAC,oBAAU,KACJL,EACFM,SAASC,KAAKC,UAAUC,IAAI,aAE5BH,SAASC,KAAKC,UAAUE,OAAO,cAEhC,CAACV,IAECG,EAKHQ,IAAAC,cAAA,OAAKC,UAAU,aACbF,IAAAC,cAAA,UAAQC,UAAU,mBAAmBC,QAnBlBC,KACrBd,GAAaD,KAmBRA,EAAW,aAAe,aAG7BW,IAAAC,cAAA,UAAI,4BACJD,IAAAC,cAAA,SAAG,uEAEHD,IAAAC,cAAA,YACEI,MAAOlB,GAAaI,EACpBe,SAtCoBC,IACxBnB,EAAamB,EAAEC,OAAOH,OACtBxB,EAAc0B,EAAEC,OAAOH,QAqCnBI,YAAY,0BAGdT,IAAAC,cAAA,OAAKC,UAAU,aACbF,IAAAC,cAAA,UAAQE,QAASnB,GAAYD,EAAW,UAAY,qBACpDiB,IAAAC,cAAA,UAAQE,QA/CSO,IAAMC,IAAkBD,eAAe,CAAEE,YAAY,EAAMC,SAAU,WA+CrD,mBACjCb,IAAAC,cAAA,UAAQE,QAASQ,IAAkBG,eAAe,kBAClDd,IAAAC,cAAA,UAAQE,QAzCIY,KAChBlC,EAAc,IACdO,EAAa,MAuCmB,SAAc,MAtBvCY,IAAAC,cAAA,SAAG,sDC3BCe,MAZSC,IAClBA,GAAeA,aAAuBC,UACxC,6BAAqBC,KAAKC,IAAkD,IAAjD,OAAEC,EAAM,OAAEC,EAAM,OAAEC,EAAM,OAAEC,EAAM,QAAEC,GAASL,EACpEC,EAAOJ,GACPK,EAAOL,GACPM,EAAON,GACPO,EAAOP,GACPQ,EAAQR,MCDDS,IAASC,WAAWhC,SAASiC,eAAe,SACpDC,OACH7B,IAAAC,cAACD,IAAM8B,WAAU,KACf9B,IAAAC,cAACtB,EAAG,QAORqC,M","file":"static/js/main.b3d3e8b6.chunk.js","sourcesContent":["import \"./App.css\";\nimport React from 'react';\nimport SpeechRecognition, { useSpeechRecognition } from \"react-speech-recognition\";\nimport useClipboard from \"react-use-clipboard\";\nimport { useState, useEffect } from \"react\";\n\nfunction App() {\n  const [textToCopy, setTextToCopy] = useState(\"\");\n  const [isCopied, setCopied] = useClipboard(textToCopy, { successDuration: 1000 });\n  const [typedText, setTypedText] = useState(\"\"); // State for typed text\n  const [darkMode, setDarkMode] = useState(false); // State for Dark Mode\n\n  const startListening = () => SpeechRecognition.startListening({ continuous: true, language: \"en-IN\" });\n  const { transcript, browserSupportsSpeechRecognition } = useSpeechRecognition();\n\n  const handleTextChange = (e) => {\n    setTypedText(e.target.value); // Update typedText state\n    setTextToCopy(e.target.value); // Sync textToCopy with typedText\n  };\n\n  const clearText = () => {\n    setTextToCopy(\"\");\n    setTypedText(\"\"); // Clear both speech and typed text\n  };\n\n  const toggleDarkMode = () => {\n    setDarkMode(!darkMode);\n  };\n\n  // Effect to add/remove dark mode class to body\n  useEffect(() => {\n    if (darkMode) {\n      document.body.classList.add(\"dark-mode\");\n    } else {\n      document.body.classList.remove(\"dark-mode\");\n    }\n  }, [darkMode]);\n\n  if (!browserSupportsSpeechRecognition) {\n    return <p>Your browser does not support Speech Recognition.</p>;\n  }\n\n  return (\n    <div className=\"container\">\n      <button className=\"toggle-dark-mode\" onClick={toggleDarkMode}>\n        {darkMode ? \"Light Mode\" : \"Dark Mode\"}\n      </button>\n\n      <h2>Speech to Text Converter</h2>\n      <p>Convert speech from the microphone to text and type to add or edit.</p>\n\n      <textarea\n        value={typedText || transcript} // Display either typed text or speech transcript\n        onChange={handleTextChange}\n        placeholder=\"Type or speak here...\"\n      />\n\n      <div className=\"btn-style\">\n        <button onClick={setCopied}>{isCopied ? \"Copied!\" : \"Copy to clipboard\"}</button>\n        <button onClick={startListening}>Start Listening</button>\n        <button onClick={SpeechRecognition.stopListening}>Stop Listening</button>\n        <button onClick={clearText}>Clear</button> {/* Clear button */}\n      </div>\n    </div>\n  );\n}\n\nexport default App;\n","const reportWebVitals = onPerfEntry => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom/client';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nconst root = ReactDOM.createRoot(document.getElementById('root'));\nroot.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}